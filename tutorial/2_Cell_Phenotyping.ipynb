{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Tutorial 2: Hierarchical Cell Phenotyping\n",
    "# ==============================================================================\n",
    "# Goal: Classify single-cell patches using the two-stage PhenoSSP framework.\n",
    "# Logic:\n",
    "#   Stage 1: Coarse Classification (Epithelial vs. Immune vs. Other)\n",
    "#   Stage 2: Fine-grained Classification (Only for Immune cells)\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# --- 1. Setup Environment ---\n",
    "# Add project root to path to import 'phenossp' modules\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\")) # For .py script\n",
    "# current_dir = os.getcwd() # Use this for Notebook\n",
    "project_root = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "from phenossp.vision_transformer import vit_small\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "WEIGHTS_PATH = os.path.join(project_root, 'phenossp', 'weights', 'phenossp_final.pth')\n",
    "DEMO_DATA_DIR = os.path.join(project_root, 'demo_data', 'patches')\n",
    "\n",
    "# Define Label Maps (Must match training)\n",
    "COARSE_LABELS = {0: 'Epithelial', 1: 'Immune', 2: 'Other'}\n",
    "IMMUNE_LABELS = {\n",
    "    0: 'CD3+CD4+CD8-',   # Helper T\n",
    "    1: 'CD3+CD4-CD8+',   # Cytotoxic T\n",
    "    2: 'CD3-CD4+CD8-',   # Other CD4+\n",
    "    3: 'CD3+CD4-CD8-',   # Other T\n",
    "    4: 'CD4+FoxP3+'      # Treg\n",
    "}\n",
    "\n",
    "print(f\"ðŸ”§ Device: {DEVICE}\")\n",
    "print(f\"ðŸ“‚ Loading weights from: {WEIGHTS_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Define the Hierarchical Model Wrapper ---\n",
    "# In a real scenario, this might be imported from `phenossp.model`\n",
    "# Here we define it explicitly to show the logic to the reviewer.\n",
    "\n",
    "class PhenoSSP_Hierarchical(nn.Module):\n",
    "    def __init__(self, num_coarse=3, num_immune=5, embed_dim=384):\n",
    "        super().__init__()\n",
    "        # 1. Backbone (ViT-S/16)\n",
    "        self.backbone = vit_small(patch_size=16, embed_dim=embed_dim, num_classes=0) \n",
    "        \n",
    "        # 2. Stage 1: Coarse Head\n",
    "        self.coarse_head = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_coarse)\n",
    "        )\n",
    "        \n",
    "        # 3. Stage 2: Immune Expert Head\n",
    "        self.immune_head = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_immune)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features (Batch, 384)\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        # Always run coarse classification\n",
    "        coarse_logits = self.coarse_head(features)\n",
    "        \n",
    "        # Run immune classification (we compute it for all, but only use it if Coarse==Immune)\n",
    "        immune_logits = self.immune_head(features)\n",
    "        \n",
    "        return coarse_logits, immune_logits\n",
    "\n",
    "# Initialize and Load Weights\n",
    "def load_model(weights_path):\n",
    "    model = PhenoSSP_Hierarchical().to(DEVICE)\n",
    "    \n",
    "    if os.path.exists(weights_path):\n",
    "        # Allow loading standard state_dict or checkpoint dict\n",
    "        checkpoint = torch.load(weights_path, map_location=DEVICE)\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            state_dict = checkpoint['model_state_dict']\n",
    "        else:\n",
    "            state_dict = checkpoint\n",
    "            \n",
    "        # Handle prefix matching if necessary (e.g. removing 'module.')\n",
    "        clean_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "        \n",
    "        # Load (strict=False allows flexibility if auxiliary keys exist)\n",
    "        model.load_state_dict(clean_state_dict, strict=False)\n",
    "        print(\"âœ… Model weights loaded successfully.\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ Warning: Weight file not found at {weights_path}. Initializing with random weights for demo.\")\n",
    "        \n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_model(WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Data Loading Helper ---\n",
    "def load_patch(patch_path):\n",
    "    \"\"\"\n",
    "    Loads a .npy patch and prepares it for the model.\n",
    "    Input NPY shape: (7, 64, 64) -> Output Tensor: (1, 7, 64, 64)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        patch = np.load(patch_path)\n",
    "        \n",
    "        # Normalize (Simple Min-Max for demo)\n",
    "        # In production, use the exact normalization statistics from training\n",
    "        patch = (patch - patch.min()) / (patch.max() - patch.min() + 1e-8)\n",
    "        \n",
    "        # Convert to Tensor\n",
    "        tensor = torch.from_numpy(patch).float().unsqueeze(0) # Add batch dim\n",
    "        return tensor.to(DEVICE), patch\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {patch_path}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Run Inference Pipeline ---\n",
    "print(\"\\nðŸš€ Starting Inference on Demo Patches...\\n\")\n",
    "\n",
    "# Get list of demo patches\n",
    "patch_files = [f for f in os.listdir(DEMO_DATA_DIR) if f.endswith('.npy')]\n",
    "patch_files.sort()\n",
    "\n",
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(1, min(5, len(patch_files)), figsize=(15, 4))\n",
    "if len(patch_files) == 1: axes = [axes]\n",
    "\n",
    "for i, filename in enumerate(patch_files[:5]):\n",
    "    # A. Load Data\n",
    "    patch_path = os.path.join(DEMO_DATA_DIR, filename)\n",
    "    input_tensor, raw_patch = load_patch(patch_path)\n",
    "    \n",
    "    if input_tensor is None: continue\n",
    "    \n",
    "    # B. Model Prediction\n",
    "    with torch.no_grad():\n",
    "        coarse_logits, immune_logits = model(input_tensor)\n",
    "        \n",
    "        # -- Stage 1 Decision --\n",
    "        coarse_probs = torch.softmax(coarse_logits, dim=1)\n",
    "        coarse_pred_idx = torch.argmax(coarse_probs, dim=1).item()\n",
    "        coarse_label = COARSE_LABELS[coarse_pred_idx]\n",
    "        coarse_conf = coarse_probs[0, coarse_pred_idx].item()\n",
    "        \n",
    "        # -- Stage 2 Decision (Conditional) --\n",
    "        final_label = coarse_label\n",
    "        final_conf = coarse_conf\n",
    "        is_immune = (coarse_label == 'Immune')\n",
    "        \n",
    "        if is_immune:\n",
    "            immune_probs = torch.softmax(immune_logits, dim=1)\n",
    "            immune_pred_idx = torch.argmax(immune_probs, dim=1).item()\n",
    "            fine_label = IMMUNE_LABELS[immune_pred_idx]\n",
    "            fine_conf = immune_probs[0, immune_pred_idx].item()\n",
    "            \n",
    "            final_label = f\"{fine_label} (Immune)\"\n",
    "            final_conf = fine_conf  # Or average of both, depending on logic\n",
    "\n",
    "    # C. Print Result\n",
    "    print(f\"[{filename}] -> Stage 1: {coarse_label} ({coarse_conf:.2f})\", end=\"\")\n",
    "    if is_immune:\n",
    "        print(f\" -> Stage 2: {fine_label} ({fine_conf:.2f})\")\n",
    "    else:\n",
    "        print(\" -> Stage 2: Skipped (Non-Immune)\")\n",
    "\n",
    "    # D. Visualize\n",
    "    # Composite: R=PanCK, G=CD8, B=DAPI\n",
    "    rgb = np.zeros((64, 64, 3))\n",
    "    rgb[..., 0] = raw_patch[3] # PanCK\n",
    "    rgb[..., 1] = raw_patch[1] # CD8\n",
    "    rgb[..., 2] = raw_patch[0] # DAPI\n",
    "    \n",
    "    if i < len(axes):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(np.clip(rgb * 1.5, 0, 1))\n",
    "        ax.set_title(f\"Pred: {final_label.split(' ')[0]}\\nConf: {final_conf:.2f}\", fontsize=10, color='green')\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
