#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Plotting Script for Figure 4: Interpretability & Feature Space
==============================================================
This script reproduces the interpretability figures:
1. Figure 4A: t-SNE Visualization of the learned feature space (Cell Type Separation).
2. Figure 4B: Subcellular Attention Maps (Visualizing model focus).

Usage:
    python plotting/plot_figure_4.py \
        --feature_csv ./results/evaluation/extracted_features.csv \
        --image_dir ./results/interpretability \
        --output_dir ./results/figures
"""

import os
import argparse
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import glob
import matplotlib.image as mpimg

# --- Configuration ---
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams.update({'font.size': 12, 'font.family': 'sans-serif'})

# Color Palette for Cell Types (Consistent with Paper)
PALETTE = {
    'Epithelial': '#1f77b4',       # Blue
    'Tumor': '#1f77b4',            # Blue (Alias)
    'Immune': '#2ca02c',           # Green
    'CD8+ T': '#98df8a',           # Light Green
    'CD4+ Treg': '#d62728',        # Red
    'Other': '#7f7f7f'             # Grey
}

def generate_synthetic_features(n_samples=500):
    """
    Generates synthetic high-dimensional data for Demo mode.
    Simulates 3 distinct clusters (Epithelial, Immune, Other).
    """
    print("ℹ️ Generating synthetic features for demo...")
    from sklearn.datasets import make_blobs
    X, y_idx = make_blobs(n_samples=n_samples, centers=3, n_features=384, random_state=42, cluster_std=5.0)
    
    labels = []
    mapping = {0: 'Epithelial', 1: 'Immune', 2: 'Other'}
    for idx in y_idx:
        labels.append(mapping[idx])
        
    return X, np.array(labels)

def plot_tsne_embedding(features, labels, save_path):
    """
    Figure 4A: t-SNE Visualization
    Pipeline: Standard Scaler -> PCA (50 dims) -> t-SNE (2 dims)
    """
    print(f"--> Running t-SNE on {features.shape[0]} samples with {features.shape[1]} dimensions...")
    
    # 1. Preprocessing
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(features)
    
    # 2. PCA Initialization (Speeds up t-SNE and improves stability)
    if X_scaled.shape[1] > 50:
        pca = PCA(n_components=50, random_state=42)
        X_pca = pca.fit_transform(X_scaled)
    else:
        X_pca = X_scaled

    # 3. t-SNE
    tsne = TSNE(n_components=2, perplexity=30, random_state=42, init='pca', learning_rate='auto')
    X_embedded = tsne.fit_transform(X_pca)
    
    # 4. Plotting
    plt.figure(figsize=(8, 8))
    
    # Create DataFrame for Seaborn
    df_plot = pd.DataFrame(X_embedded, columns=['t-SNE 1', 't-SNE 2'])
    df_plot['Cell Type'] = labels
    
    # Map colors if key exists, else use default palette
    unique_labels = np.unique(labels)
    colors = {k: PALETTE.get(k, sns.color_palette("tab10")[i % 10]) 
              for i, k in enumerate(unique_labels)}
    
    sns.scatterplot(data=df_plot, x='t-SNE 1', y='t-SNE 2', hue='Cell Type', 
                    palette=colors, s=60, alpha=0.8, edgecolor='w', linewidth=0.5)
    
    plt.title('Figure 4A: Learned Feature Space (t-SNE)', fontsize=16, fontweight='bold')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"✅ Saved Figure 4A to {save_path}")

def plot_saliency_panel(image_dir, save_path):
    """
    Figure 4B: Subcellular Attention Examples
    Stitches together existing visualization images generated by pipeline/05_visual_interpretability.py
    """
    # Look for PNG files generated by the interpretability script
    # Expected format: Attn_{Marker}_{CellID}_Score_{Score}.png
    image_files = sorted(glob.glob(os.path.join(image_dir, "Attn_*.png")))
    
    if not image_files:
        print(f"⚠️ No saliency images found in {image_dir}. Skipping Figure 4B.")
        print("   (Run 'python pipeline/05_visual_interpretability.py' first to generate them)")
        return

    # Select top 3 examples (or random)
    selected_files = image_files[:3]
    
    # Create Panel
    n_images = len(selected_files)
    fig, axes = plt.subplots(n_images, 1, figsize=(12, 4 * n_images))
    if n_images == 1: axes = [axes]
    
    for ax, img_path in zip(axes, selected_files):
        img = mpimg.imread(img_path)
        ax.imshow(img)
        ax.axis('off')
        
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"✅ Saved Figure 4B (Panel of {n_images} cells) to {save_path}")

def main():
    parser = argparse.ArgumentParser(description="Reproduce Figure 4 (Interpretability)")
    parser.add_argument('--feature_csv', type=str, default=None, 
                        help="Path to CSV containing features (columns 0-383) and 'cell_type' label.")
    parser.add_argument('--image_dir', type=str, default='./results/interpretability',
                        help="Directory containing saliency map images (from Step 4).")
    parser.add_argument('--output_dir', type=str, default='./results/figures', help="Where to save figures")
    args = parser.parse_args()
    
    os.makedirs(args.output_dir, exist_ok=True)
    
    print("--- Generating Figure 4 (Interpretability) ---")
    
    # --- Part 1: Feature Space (Figure 4A) ---
    if args.feature_csv and os.path.exists(args.feature_csv):
        print(f"--> Loading features from {args.feature_csv}")
        try:
            df = pd.read_csv(args.feature_csv)
            # Assume features are numeric columns and label is 'cell_type' or 'label'
            label_col = 'cell_type' if 'cell_type' in df.columns else 'label'
            if label_col not in df.columns:
                print(f"⚠️ Label column not found. Skipping t-SNE.")
            else:
                # Extract features (drop non-numeric and label)
                feature_cols = df.select_dtypes(include=[np.number]).columns
                X = df[feature_cols].values
                y = df[label_col].values
                
                # Check dimensions (ViT usually 384)
                if X.shape[1] > 10: 
                    plot_tsne_embedding(X, y, os.path.join(args.output_dir, 'Figure_4A_tSNE.png'))
                else:
                    print("⚠️ Not enough feature dimensions for t-SNE.")
        except Exception as e:
            print(f"❌ Error processing CSV: {e}")
    else:
        # Run Demo Mode
        X, y = generate_synthetic_features()
        plot_tsne_embedding(X, y, os.path.join(args.output_dir, 'Figure_4A_tSNE_Demo.png'))

    # --- Part 2: Saliency Maps (Figure 4B) ---
    plot_saliency_panel(args.image_dir, os.path.join(args.output_dir, 'Figure_4B_Saliency_Panel.png'))

if __name__ == "__main__":
    main()